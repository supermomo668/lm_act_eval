{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/opadmin/llama2d_opentable/lm_act_eval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change dir to ml repo at ml/ root (if you started in notebook/)\n",
    "os.chdir('../')\n",
    "print(Path.cwd())\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opadmin/anaconda3/envs/eval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# read dataset into datasets\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "dataset_name = \"five-star-trajectories\"\n",
    "dataset_path = Path(f\"lm_act_eval/.cache/{dataset_name }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud not set up, skipping import of providers.gemini_utils.generate_from_gemini_completion\n",
      "Google Cloud not set up, skipping import of vertexai.preview.generative_models.Image and llms.generate_from_gemini_completion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opadmin/anaconda3/envs/eval/lib/python3.11/site-packages/beartype/_util/hint/pep/utilpeptest.py:311: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.Mapping[str, gymnasium.spaces.space.Space[typing.Any]] deprecated by PEP 585. This hint is scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". For further commentary and alternatives, see also:\n",
      "    https://beartype.readthedocs.io/en/latest/api_roar/#pep-585-deprecations\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud not set up, skipping import of providers.gemini_utils.generate_from_gemini_completion\n",
      "Google Cloud not set up, skipping import of vertexai.preview.generative_models.Image and llms.generate_from_gemini_completion\n"
     ]
    }
   ],
   "source": [
    "from lm_act_eval.evaluation_harness.helper_functions.multion import (\n",
    "  action_prefix,\n",
    "  clean_extracted_text,\n",
    "  extract_thought,\n",
    "  extract_action,\n",
    "  extract_explanation,\n",
    "  ParseChatCompletion\n",
    ")\n",
    "from lm_act_eval.evaluation_harness.utils.url import is_screenshot_url_accessible\n",
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'session_id', 'idx_in_session', '_id', 'event_id',\n",
      "       'parent_id', 'event_type', 'event_name', 'config', 'children_ids',\n",
      "       'inputs', 'outputs', 'error', 'start_time', 'end_time', 'metadata',\n",
      "       'feedback', 'metrics', 'user_properties', 'source', 'duration',\n",
      "       'project_id', 'tenant', 'QUERY', 'URL', 'DOM', 'RULES', 'USER_CONTEXT',\n",
      "       'PREV_ACTIONS', 'chat_history', 'CURRENT_TIME', 'planPrompt',\n",
      "       'previousActionsRepetitionPrompt', 'chat_completion_messages',\n",
      "       'ground_truth', 'screenshot', 'prompt', 'internal_metadata',\n",
      "       'GPTV response', 'chat_completion_messages_content'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "traj_df = pd.read_csv(dataset_path/'csv/data+gptv.csv')\n",
    "print(traj_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoevals.string import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_action_fs = lambda x: extract_action(x) if type(x) == str else \"\"\n",
    "extract_thought_fs = lambda x: extract_thought(x) if type(x) == str else \"\"\n",
    "extract_explanation_fs = lambda x: extract_explanation(x) if type(x) == str else \"\"\n",
    "process_fs = {\n",
    "  \"action\": extract_action_fs,\n",
    "  \"thought\": extract_thought_fs,\n",
    "  \"explanation\": extract_thought_fs\n",
    "}\n",
    "metric_registry = {\n",
    "    \"edit\": Levenshtein()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3382/3382 [00:00<00:00, 142542.69it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 105897.16it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 106947.86it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 910061.98it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 437529.26it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 435822.05it/s]\n"
     ]
    }
   ],
   "source": [
    "metric_comp = pd.DataFrame()\n",
    "gt_col = \"ground_truth\"\n",
    "gen_col = \"GPTV\"\n",
    "# Prepare metric input columns\n",
    "for c in [gt_col, gen_col]:\n",
    "  for k, func in process_fs.items():\n",
    "    traj_df[c+'_'+k] = traj_df[c].progress_apply(func)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_metrics = {\n",
    "    \"Actions\": {\"edit\": \"edit\"}\n",
    "}\n",
    "metric_registry = {\n",
    "    \"edit\": Levenshtein()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth_action_trajectory</th>\n",
       "      <th>ground_truth_thought_trajectory</th>\n",
       "      <th>ground_truth_explanation_trajectory</th>\n",
       "      <th>GPTV_action_trajectory</th>\n",
       "      <th>GPTV_thought_trajectory</th>\n",
       "      <th>GPTV_explanation_trajectory</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0007f9ea-9830-4c63-a560-3b133b2b57ca</th>\n",
       "      <td>[CLICK 3, CLICK 40, CLICK 4, TYPE 7 \"rear left...</td>\n",
       "      <td>[PLAN: To remove the item that was just added ...</td>\n",
       "      <td>[PLAN: To remove the item that was just added ...</td>\n",
       "      <td>[, , , , , , ]</td>\n",
       "      <td>[, , , , , , ]</td>\n",
       "      <td>[, , , , , , ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         ground_truth_action_trajectory  \\\n",
       "session_id                                                                                \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca  [CLICK 3, CLICK 40, CLICK 4, TYPE 7 \"rear left...   \n",
       "\n",
       "                                                        ground_truth_thought_trajectory  \\\n",
       "session_id                                                                                \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca  [PLAN: To remove the item that was just added ...   \n",
       "\n",
       "                                                    ground_truth_explanation_trajectory  \\\n",
       "session_id                                                                                \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca  [PLAN: To remove the item that was just added ...   \n",
       "\n",
       "                                     GPTV_action_trajectory  \\\n",
       "session_id                                                    \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca         [, , , , , , ]   \n",
       "\n",
       "                                     GPTV_thought_trajectory  \\\n",
       "session_id                                                     \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca          [, , , , , , ]   \n",
       "\n",
       "                                     GPTV_explanation_trajectory  \n",
       "session_id                                                        \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca              [, , , , , , ]  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trajectory\n",
    "metric_comp_traj_df = pd.DataFrame()\n",
    "def extract_trajectory(traj_df, target_col: str='ground_truth') -> List:\n",
    "  sorted_grouped_texts = (\n",
    "    traj_df.sort_values(by=['session_id', 'idx_in_session'])\n",
    "    .groupby('session_id')[target_col]\n",
    "    .apply(list)\n",
    "  )\n",
    "  return sorted_grouped_texts\n",
    "\n",
    "for c in [gt_col, gen_col]:\n",
    "  for k, func in process_fs.items():\n",
    "    metric_comp_traj_df[c+'_'+k+'_trajectory'] = extract_trajectory(traj_df, target_col=c+'_'+k)\n",
    "  \n",
    "# trajectory_gt = extract_trajectory(target_col=gt_col)\n",
    "# trajectory_target = extract_trajectory(target_col=gen_col)\n",
    "metric_comp_traj_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edit_action</th>\n",
       "      <th>edit_thought</th>\n",
       "      <th>edit_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04496</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.055535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edit_action  edit_thought  edit_explanation\n",
       "0      0.04496      0.055359          0.055535"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_metrics = pd.DataFrame()\n",
    "for k in process_fs:\n",
    "  for m, func in metric_registry.items():\n",
    "    traj_metrics[m+'_'+k] = traj_df[gt_col+'_'+k].apply(\n",
    "      lambda x: func(x, traj_df[gen_col+'_'+k]).score)\n",
    "traj_metrics.head(2)\n",
    "traj_metrics_comp = traj_metrics.mean().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_trajectory(dataset):\n",
    "#     \"\"\"\n",
    "#     eligible dataset\n",
    "#     \"\"\"\n",
    "#     metric_results = []\n",
    "#     for index, row in dataset[eligible].iterrows():\n",
    "#         result_row = {}\n",
    "#         for metric_config in config_metrics:\n",
    "#             metric_name = metric_config[\"name\"]\n",
    "#             if metric_registry.get(metric_name):\n",
    "#                 metric_func = metric_registry[metric_name]\n",
    "#                 result_row[metric_name] = metric_func(row)\n",
    "#         metric_results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/opadmin/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/opadmin/llama2d_opentable/lm_act_eval/wandb/run-20240323_032309-z3u9ajx7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/multion-agi/trajectory_eval/runs/z3u9ajx7' target=\"_blank\">opentable-GPTV</a></strong> to <a href='https://wandb.ai/multion-agi/trajectory_eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/multion-agi/trajectory_eval' target=\"_blank\">https://wandb.ai/multion-agi/trajectory_eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/multion-agi/trajectory_eval/runs/z3u9ajx7' target=\"_blank\">https://wandb.ai/multion-agi/trajectory_eval/runs/z3u9ajx7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log data\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "wandb.login(relogin=True)\n",
    "run = wandb.init(\n",
    "  project='trajectory_eval', name=\"opentable-GPTV\", entity=\"multion-agi\",\n",
    "  reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtifactManifestEntry(path='opentable-trajectory_comparison.table.json', digest='BDwjRNg7S/8yzW9UpY9ezw==', size=1994147, local_path='/home/opadmin/.local/share/wandb/artifacts/staging/tmpby7e9rn0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opentable_artifact = wandb.Artifact(\"opentable_trajectories_gptv_compare.v0\", type=\"dataset\")\n",
    "# opentable_table = wandb.Table(dataframe=traj_df_new)\n",
    "opentable_table_traj = wandb.Table(dataframe=metric_comp_traj_df)\n",
    "#\n",
    "# opentable_artifact.add(opentable_table, \"opentable\")\n",
    "opentable_artifact.add(opentable_table_traj, \"opentable-trajectory_comparison\")\n",
    "# opentable_artifact.add_file(str(dataset_path/'csv/data+gptv.csv'))\n",
    "# opentable_artifact.add_file(str(dataset_path/'csv/data+gptv-eligible.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a W&B run to log data\n",
    "\n",
    "# Log the table to visualize with a run...\n",
    "run.log({\n",
    "  \"opentable_gptv_metric_comparison\": metric_comp_traj_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({\n",
    "  'opentable_gptv_metric_edit': traj_metrics_comp })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
