{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/opadmin/llama2d_opentable/lm_act_eval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change dir to ml repo at ml/ root (if you started in notebook/)\n",
    "os.chdir('../')\n",
    "print(Path.cwd())\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opadmin/anaconda3/envs/eval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['session_id', 'idx_in_session', '_id', 'event_id', 'parent_id',\n",
      "       'event_type', 'event_name', 'config', 'children_ids', 'inputs',\n",
      "       'outputs', 'error', 'start_time', 'end_time', 'metadata', 'feedback',\n",
      "       'metrics', 'user_properties', 'source', 'duration', 'project_id',\n",
      "       'tenant', 'QUERY', 'URL', 'DOM', 'RULES', 'USER_CONTEXT',\n",
      "       'PREV_ACTIONS', 'chat_history', 'CURRENT_TIME', 'planPrompt',\n",
      "       'previousActionsRepetitionPrompt', 'chat_completion_messages',\n",
      "       'ground_truth', 'screenshot', 'prompt', 'internal_metadata'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>idx_in_session</th>\n",
       "      <th>_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_name</th>\n",
       "      <th>config</th>\n",
       "      <th>children_ids</th>\n",
       "      <th>inputs</th>\n",
       "      <th>...</th>\n",
       "      <th>PREV_ACTIONS</th>\n",
       "      <th>chat_history</th>\n",
       "      <th>CURRENT_TIME</th>\n",
       "      <th>planPrompt</th>\n",
       "      <th>previousActionsRepetitionPrompt</th>\n",
       "      <th>chat_completion_messages</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>screenshot</th>\n",
       "      <th>prompt</th>\n",
       "      <th>internal_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ce3bf1c8-371a-4adb-98e6-2cce19c1aff5</td>\n",
       "      <td>0</td>\n",
       "      <td>65f0c5d705cef8bdb70153a9</td>\n",
       "      <td>cc3d0d22-4759-43d8-a688-d174ca94f9dd</td>\n",
       "      <td>ce3bf1c8-371a-4adb-98e6-2cce19c1aff5</td>\n",
       "      <td>model</td>\n",
       "      <td>Model Completion</td>\n",
       "      <td>{'model': 'gpt-4-1106-preview', 'provider': 'u...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'QUERY': 'Find a restaurant with vegetarian o...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tuesday, March 12, 2024 at 4:14:11 PM CDT</td>\n",
       "      <td>IMPORTANT: If the objective is complex, compri...</td>\n",
       "      <td>**PREVIOUS ACTIONS Repetition**:\\n- Review the...</td>\n",
       "      <td>[{'role': 'system', 'content': '**Goal**: Let\\...</td>\n",
       "      <td>PLAN: To find a restaurant with vegetarian opt...</td>\n",
       "      <td>https://multion-client-screenshots.s3.us-east-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ce3bf1c8-371a-4adb-98e6-2cce19c1aff5</td>\n",
       "      <td>1</td>\n",
       "      <td>65f0c60705cef8bdb70153ab</td>\n",
       "      <td>44b78fc2-24e2-40e5-b39d-e887a7129587</td>\n",
       "      <td>ce3bf1c8-371a-4adb-98e6-2cce19c1aff5</td>\n",
       "      <td>model</td>\n",
       "      <td>Model Completion</td>\n",
       "      <td>{'model': 'gpt-4-1106-preview', 'provider': 'u...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'QUERY': 'Find a restaurant with vegetarian o...</td>\n",
       "      <td>...</td>\n",
       "      <td>- I am searching for restaurants with vegetari...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Find a restauran...</td>\n",
       "      <td>Tuesday, March 12, 2024 at 4:15:02 PM CDT</td>\n",
       "      <td>IMPORTANT: If the objective is complex, compri...</td>\n",
       "      <td>**PREVIOUS ACTIONS Repetition**:\\n- Review the...</td>\n",
       "      <td>[{'role': 'system', 'content': '**Goal**: Let\\...</td>\n",
       "      <td>The search for \"vegetarian\" in St. Louis has y...</td>\n",
       "      <td>https://multion-client-screenshots.s3.us-east-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             session_id idx_in_session  \\\n",
       "0  ce3bf1c8-371a-4adb-98e6-2cce19c1aff5              0   \n",
       "1  ce3bf1c8-371a-4adb-98e6-2cce19c1aff5              1   \n",
       "\n",
       "                        _id                              event_id  \\\n",
       "0  65f0c5d705cef8bdb70153a9  cc3d0d22-4759-43d8-a688-d174ca94f9dd   \n",
       "1  65f0c60705cef8bdb70153ab  44b78fc2-24e2-40e5-b39d-e887a7129587   \n",
       "\n",
       "                              parent_id event_type        event_name  \\\n",
       "0  ce3bf1c8-371a-4adb-98e6-2cce19c1aff5      model  Model Completion   \n",
       "1  ce3bf1c8-371a-4adb-98e6-2cce19c1aff5      model  Model Completion   \n",
       "\n",
       "                                              config children_ids  \\\n",
       "0  {'model': 'gpt-4-1106-preview', 'provider': 'u...           []   \n",
       "1  {'model': 'gpt-4-1106-preview', 'provider': 'u...           []   \n",
       "\n",
       "                                              inputs  ...  \\\n",
       "0  {'QUERY': 'Find a restaurant with vegetarian o...  ...   \n",
       "1  {'QUERY': 'Find a restaurant with vegetarian o...  ...   \n",
       "\n",
       "                                        PREV_ACTIONS  \\\n",
       "0                                                NaN   \n",
       "1  - I am searching for restaurants with vegetari...   \n",
       "\n",
       "                                        chat_history  \\\n",
       "0                                                 []   \n",
       "1  [{'role': 'user', 'content': 'Find a restauran...   \n",
       "\n",
       "                                CURRENT_TIME  \\\n",
       "0  Tuesday, March 12, 2024 at 4:14:11 PM CDT   \n",
       "1  Tuesday, March 12, 2024 at 4:15:02 PM CDT   \n",
       "\n",
       "                                          planPrompt  \\\n",
       "0  IMPORTANT: If the objective is complex, compri...   \n",
       "1  IMPORTANT: If the objective is complex, compri...   \n",
       "\n",
       "                     previousActionsRepetitionPrompt  \\\n",
       "0  **PREVIOUS ACTIONS Repetition**:\\n- Review the...   \n",
       "1  **PREVIOUS ACTIONS Repetition**:\\n- Review the...   \n",
       "\n",
       "                            chat_completion_messages  \\\n",
       "0  [{'role': 'system', 'content': '**Goal**: Let\\...   \n",
       "1  [{'role': 'system', 'content': '**Goal**: Let\\...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  PLAN: To find a restaurant with vegetarian opt...   \n",
       "1  The search for \"vegetarian\" in St. Louis has y...   \n",
       "\n",
       "                                          screenshot prompt  internal_metadata  \n",
       "0  https://multion-client-screenshots.s3.us-east-...    NaN                NaN  \n",
       "1  https://multion-client-screenshots.s3.us-east-...    NaN                NaN  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset into datasets\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "dataset_name = \"five-star-trajectories\"\n",
    "dataset_path = Path(f\"lm_act_eval/.cache/{dataset_name }\")\n",
    "traj_df = pd.read_csv(dataset_path/\"csv/data.csv\")\n",
    "traj_dataset = Dataset.from_pandas(traj_df)\n",
    "print(traj_df.columns)\n",
    "traj_df[traj_df.session_id==traj_df.session_id.unique()[0]]\n",
    "traj_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud not set up, skipping import of providers.gemini_utils.generate_from_gemini_completion\n",
      "Google Cloud not set up, skipping import of vertexai.preview.generative_models.Image and llms.generate_from_gemini_completion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opadmin/anaconda3/envs/eval/lib/python3.11/site-packages/beartype/_util/hint/pep/utilpeptest.py:311: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.Mapping[str, gymnasium.spaces.space.Space[typing.Any]] deprecated by PEP 585. This hint is scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". For further commentary and alternatives, see also:\n",
      "    https://beartype.readthedocs.io/en/latest/api_roar/#pep-585-deprecations\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from lm_act_eval.evaluation_harness.helper_functions.multion import (\n",
    "  action_prefix,\n",
    "  clean_extracted_text,\n",
    "  extract_thought,\n",
    "  extract_action,\n",
    "  extract_explanation,\n",
    "  ParseChatCompletion\n",
    ")\n",
    "from lm_act_eval.evaluation_harness.utils.url import is_screenshot_url_accessible\n",
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_df = pd.read_csv(dataset_path/'csv/data+gptv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_act_eval.evaluation_harness.constants import BNB_QUANTIZATION_CONFIG_8BIT, BitsAndBytesConfig\n",
    "\n",
    "from lm_act_eval.common.hf import load_model_and_tokenizer\n",
    "from lm_act_eval.evaluation_harness.evaluators.sft.utils import generate_text_and_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:46<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"MULTION-AI/feasible-morning-17-v4\"\n",
    "# Load the tokenizer and model\n",
    "bnb = True\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if not bnb:\n",
    "  model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "else:\n",
    "  quantization_config = BitsAndBytesConfig(load_in_8bit_fp32_cpu_offload=True)\n",
    "  model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, low_cpu_mem_usage=True, \n",
    "    device_map=\"auto\", quantization_config=quantization_config, \n",
    "    max_memory={**{k:'8000Mib' for k in range(0,8)}, \"cpu\": '100Gib'}\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_df_generated = generate_text_and_merge(\n",
    "    traj_df,\n",
    "    \"chat_completion_messages_content\",\n",
    "    model,\n",
    "    tokenizer,\n",
    "    model.device,\n",
    "    max_new_tokens=256,\n",
    "    batch_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_df_new_gen = traj_df.copy()\n",
    "traj_df_new_gen.to_csv(dataset_path/f'csv/data+gen_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_respsonse(\n",
    "#     row, pipeline, inp_column=\"completion_msg_content\", log=False, max_new_tokens=256):\n",
    "#     response = pipeline(\n",
    "#         row[inp_column], max_new_tokens=max_new_tokens, num_return_sequences=1)\n",
    "#     generated_text = response[0][\"generated_text\"]\n",
    "#     if log:\n",
    "#         wandb.log({\n",
    "#             \"original_text\": row[inp_column],\n",
    "#             \"generated_text\": generated_text})\n",
    "#     return generated_text\n",
    "\n",
    "# # responses = []\n",
    "# # for index, row in tqdm(traj_df.iterrows(), desc=\"generating completions\"):\n",
    "# #     responses.append(generate_respsonse(\n",
    "# #         row, inp_column=\"completion_msg_content\", log=False\n",
    "# #     ))\n",
    "# # traj_df['generated_responses'] = responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging - generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Initialize Wandb\n",
    "wandb.login()\n",
    "run = wandb.init(\n",
    "  project=\"trajectory_eval\", entity=\"multion-agi\",\n",
    "  name=f\"opentable-{model_name}\", reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentable_artifact = wandb.Artifact(f\"opentable_trajectories_eval-{model_name}\", type=\"dataset\")\n",
    "# opentable_table = wandb.Table(dataframe=traj_df_new)\n",
    "eval_generation = wandb.Table(dataframe=traj_df)\n",
    "#\n",
    "# opentable_artifact.add(opentable_table, \"opentable\")\n",
    "opentable_artifact.add(eval_generation, \"eval-generations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the table to visualize with a run...\n",
    "run.log({\"eval-generations\": eval_generation})\n",
    "# and Log as an Artifact to increase the available row limit!\n",
    "run.log_artifact(opentable_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autoevals.llm import *\n",
    "from autoevals.string import Levenshtein\n",
    "import warnings\n",
    "levenshtein_evaluator = Levenshtein()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_metrics = {\n",
    "    \"Actions\": {\"edit\": \"edit\"}\n",
    "}\n",
    "metric_registry = {\n",
    "    \"edit\": Levenshtein()\n",
    "}\n",
    "def evaluate_trajectory(dataset):\n",
    "    \"\"\"\n",
    "    eligible dataset\n",
    "    \"\"\"\n",
    "    metric_results = []\n",
    "    for index, row in dataset[eligible].iterrows():\n",
    "        result_row = {}\n",
    "        for metric_config in config_metrics:\n",
    "            metric_name = metric_config[\"name\"]\n",
    "            if metric_registry.get(metric_name):\n",
    "                metric_func = metric_registry[metric_name]\n",
    "                result_row[metric_name] = metric_func(row)\n",
    "        metric_results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/opadmin/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log data\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "wandb.login(relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentable_artifact = wandb.Artifact(\"opentable_trajectories_gptv.v0\", type=\"dataset\")\n",
    "# opentable_table = wandb.Table(dataframe=traj_df_new)\n",
    "\n",
    "opentable_table_eligible = wandb.Table(dataframe=eligible_traj_df)\n",
    "#\n",
    "# opentable_artifact.add(opentable_table, \"opentable\")\n",
    "opentable_artifact.add(opentable_table_eligible, \"opentable-eligibleonly\")\n",
    "# opentable_artifact.add_file(str(dataset_path/'csv/data+gptv.csv'))\n",
    "opentable_artifact.add_file(str(dataset_path/'csv/data+gptv-eligible.csv'))\n",
    "\n",
    "# Log the table to visualize with a run...\n",
    "run.log({\"opentable_gptv_generation\": opentable_table_eligible})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
