{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/opadmin/llama2d_opentable/lm_act_eval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change dir to ml repo at ml/ root (if you started in notebook/)\n",
    "os.chdir('../')\n",
    "print(Path.cwd())\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opadmin/anaconda3/envs/eval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# read dataset into datasets\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "dataset_name = \"five-star-trajectories\"\n",
    "dataset_path = Path(f\"lm_act_eval/.cache/{dataset_name }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud not set up, skipping import of providers.gemini_utils.generate_from_gemini_completion\n",
      "Google Cloud not set up, skipping import of vertexai.preview.generative_models.Image and llms.generate_from_gemini_completion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opadmin/anaconda3/envs/eval/lib/python3.11/site-packages/beartype/_util/hint/pep/utilpeptest.py:311: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.Mapping[str, gymnasium.spaces.space.Space[typing.Any]] deprecated by PEP 585. This hint is scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". For further commentary and alternatives, see also:\n",
      "    https://beartype.readthedocs.io/en/latest/api_roar/#pep-585-deprecations\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud not set up, skipping import of providers.gemini_utils.generate_from_gemini_completion\n",
      "Google Cloud not set up, skipping import of vertexai.preview.generative_models.Image and llms.generate_from_gemini_completion\n"
     ]
    }
   ],
   "source": [
    "from lm_act_eval.evaluation_harness.helper_functions.multion import (\n",
    "  action_prefix,\n",
    "  clean_extracted_text,\n",
    "  extract_thought,\n",
    "  extract_action,\n",
    "  extract_explanation,\n",
    "  ParseChatCompletion\n",
    ")\n",
    "from lm_act_eval.evaluation_harness.utils.url import is_screenshot_url_accessible\n",
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'session_id', 'idx_in_session', '_id', 'event_id',\n",
      "       'parent_id', 'event_type', 'event_name', 'config', 'children_ids',\n",
      "       'inputs', 'outputs', 'error', 'start_time', 'end_time', 'metadata',\n",
      "       'feedback', 'metrics', 'user_properties', 'source', 'duration',\n",
      "       'project_id', 'tenant', 'QUERY', 'URL', 'DOM', 'RULES', 'USER_CONTEXT',\n",
      "       'PREV_ACTIONS', 'chat_history', 'CURRENT_TIME', 'planPrompt',\n",
      "       'previousActionsRepetitionPrompt', 'chat_completion_messages',\n",
      "       'ground_truth', 'screenshot', 'prompt', 'internal_metadata',\n",
      "       'GPTV response', 'chat_completion_messages_content'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "traj_df = pd.read_csv(dataset_path/'csv/data+gptv.csv')\n",
    "print(traj_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoevals.string import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_action_fs = lambda x: extract_action(x) if type(x) == str else \"\"\n",
    "extract_thought_fs = lambda x: extract_thought(x) if type(x) == str else \"\"\n",
    "extract_explanation_fs = lambda x: extract_explanation(x) if type(x) == str else \"\"\n",
    "process_fs = {\n",
    "  \"action\": extract_action_fs,\n",
    "  \"thought\": extract_thought_fs,\n",
    "  \"explanation\": extract_thought_fs\n",
    "}\n",
    "metric_registry = {\n",
    "    \"edit\": Levenshtein()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3382/3382 [00:00<00:00, 142542.69it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 105897.16it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 106947.86it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 910061.98it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 437529.26it/s]\n",
      "100%|██████████| 3382/3382 [00:00<00:00, 435822.05it/s]\n"
     ]
    }
   ],
   "source": [
    "metric_comp = pd.DataFrame()\n",
    "gt_col = \"ground_truth\"\n",
    "gen_col = \"GPTV\"\n",
    "# Prepare metric input columns\n",
    "for c in [gt_col, gen_col]:\n",
    "  for k, func in process_fs.items():\n",
    "    traj_df[c+'_'+k] = traj_df[c].progress_apply(func)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_metrics = {\n",
    "    \"Actions\": {\"edit\": \"edit\"}\n",
    "}\n",
    "metric_registry = {\n",
    "    \"edit\": Levenshtein()\n",
    "}\n",
    "\n",
    "# Step break\n",
    "# compute metrics\n",
    "for m, func in metric_registry.items():\n",
    "  for k in process_fs:\n",
    "    traj_df[c+'_'+k] = traj_df[c].progress_apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth_action_trajectory</th>\n",
       "      <th>ground_truth_thought_trajectory</th>\n",
       "      <th>ground_truth_explanation_trajectory</th>\n",
       "      <th>GPTV_action_trajectory</th>\n",
       "      <th>GPTV_thought_trajectory</th>\n",
       "      <th>GPTV_explanation_trajectory</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0007f9ea-9830-4c63-a560-3b133b2b57ca</th>\n",
       "      <td>[CLICK 3, CLICK 40, CLICK 4, TYPE 7 \"rear left...</td>\n",
       "      <td>[PLAN: To remove the item that was just added ...</td>\n",
       "      <td>[PLAN: To remove the item that was just added ...</td>\n",
       "      <td>[, , , , , , ]</td>\n",
       "      <td>[, , , , , , ]</td>\n",
       "      <td>[, , , , , , ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         ground_truth_action_trajectory  \\\n",
       "session_id                                                                                \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca  [CLICK 3, CLICK 40, CLICK 4, TYPE 7 \"rear left...   \n",
       "\n",
       "                                                        ground_truth_thought_trajectory  \\\n",
       "session_id                                                                                \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca  [PLAN: To remove the item that was just added ...   \n",
       "\n",
       "                                                    ground_truth_explanation_trajectory  \\\n",
       "session_id                                                                                \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca  [PLAN: To remove the item that was just added ...   \n",
       "\n",
       "                                     GPTV_action_trajectory  \\\n",
       "session_id                                                    \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca         [, , , , , , ]   \n",
       "\n",
       "                                     GPTV_thought_trajectory  \\\n",
       "session_id                                                     \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca          [, , , , , , ]   \n",
       "\n",
       "                                     GPTV_explanation_trajectory  \n",
       "session_id                                                        \n",
       "0007f9ea-9830-4c63-a560-3b133b2b57ca              [, , , , , , ]  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trajectory\n",
    "metric_comp_traj_df = pd.DataFrame()\n",
    "def extract_trajectory(traj_df, target_col: str='ground_truth') -> List:\n",
    "  sorted_grouped_texts = (\n",
    "    traj_df.sort_values(by=['session_id', 'idx_in_session'])\n",
    "    .groupby('session_id')[target_col]\n",
    "    .apply(list)\n",
    "  )\n",
    "  return sorted_grouped_texts\n",
    "\n",
    "for c in [gt_col, gen_col]:\n",
    "  for k, func in process_fs.items():\n",
    "    metric_comp_traj_df[c+'_'+k+'_trajectory'] = extract_trajectory(traj_df, target_col=c+'_'+k)\n",
    "  \n",
    "# trajectory_gt = extract_trajectory(target_col=gt_col)\n",
    "# trajectory_target = extract_trajectory(target_col=gen_col)\n",
    "metric_comp_traj_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2792572238.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[85], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(metric_registry.get('edit')(metric_comp_traj_df, )\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "for c in [gt_col, gen_col]:\n",
    "  for k, func in process_fs.items():\n",
    "    \n",
    "    distances = traj_df[c+'_'+k].apply(lambda x: distance(x, extracted2.loc[x.name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_trajectory(dataset):\n",
    "    \"\"\"\n",
    "    eligible dataset\n",
    "    \"\"\"\n",
    "    metric_results = []\n",
    "    for index, row in dataset[eligible].iterrows():\n",
    "        result_row = {}\n",
    "        for metric_config in config_metrics:\n",
    "            metric_name = metric_config[\"name\"]\n",
    "            if metric_registry.get(metric_name):\n",
    "                metric_func = metric_registry[metric_name]\n",
    "                result_row[metric_name] = metric_func(row)\n",
    "        metric_results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/opadmin/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log data\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "wandb.login(relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtifactManifestEntry(path='opentable-trajectory_comparison.table.json', digest='BDwjRNg7S/8yzW9UpY9ezw==', size=1994147, local_path='/home/opadmin/.local/share/wandb/artifacts/staging/tmp_i4jhxjd')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opentable_artifact = wandb.Artifact(\"opentable_trajectories_gptv_compare.v0\", type=\"dataset\")\n",
    "# opentable_table = wandb.Table(dataframe=traj_df_new)\n",
    "opentable_table_traj = wandb.Table(dataframe=metric_comp_traj_df)\n",
    "#\n",
    "# opentable_artifact.add(opentable_table, \"opentable\")\n",
    "opentable_artifact.add(opentable_table_traj, \"opentable-trajectory_comparison\")\n",
    "# opentable_artifact.add_file(str(dataset_path/'csv/data+gptv.csv'))\n",
    "# opentable_artifact.add_file(str(dataset_path/'csv/data+gptv-eligible.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /home/opadmin/anaconda3/envs/eval/lib/python3.11/site-packages/wandb/sdk/wandb_init.py 854 getcaller\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "Run initialization has timed out after 90.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start a W&B run to log data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrajectory_eval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopentable-GPTV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreinit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Log the table to visualize with a run...\u001b[39;00m\n\u001b[1;32m      4\u001b[0m run\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopentable_gptv_metric_comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m: metric_comp_traj_df})\n",
      "File \u001b[0;32m~/anaconda3/envs/eval/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1195\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n",
      "File \u001b[0;32m~/anaconda3/envs/eval/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1176\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1174\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/eval/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:785\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    783\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m--> 785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 90.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
     ]
    }
   ],
   "source": [
    "# Start a W&B run to log data\n",
    "run = wandb.init(project='trajectory_eval', name=\"opentable-GPTV\", reinit=True)\n",
    "# Log the table to visualize with a run...\n",
    "run.log({\"opentable_gptv_metric_comparison\": metric_comp_traj_df})\n",
    "\n",
    "# and Log as an Artifact to increase the available row limit!\n",
    "# run.log_artifact(opentable_artifact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
